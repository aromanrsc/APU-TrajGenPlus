{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4134b24-15ea-4616-8ff7-688870a3acf5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original path to the San Francisco dataset files\n",
    "DATASET_PATH = \"../original_datasets/SanFranciscoDataset/cabspottingdata.tar/cabspottingdata/\"\n",
    "\n",
    "# Map with all the files in the DATASET_PATH\n",
    "INPUT_FILES = map(lambda x: DATASET_PATH  + x, os.listdir(DATASET_PATH))\n",
    "\n",
    "# Paths where to save proccessed files\n",
    "\n",
    "# Pickle file path with original data, without filtering based on occupancy\n",
    "ORIGINAL_FILE = \"../data/SanFrancisco/original_trajectories_all.pkl\"\n",
    "\n",
    "# Pickle file path with only occupied trajectories\n",
    "OCCUPIED_FILE = \"../data/SanFrancisco/occupied_trajectories_all.pkl\"\n",
    "\n",
    "# Pickle file path with occupied trajectories\n",
    "NOT_OCCUPIED_FILE = \"../data/SanFrancisco/not_occupied_trajectories_all.pkl\"\n",
    "\n",
    "# Pickle file path with all trajectories extracted\n",
    "TRAJECTORIES_FILE = \"../data/SanFrancisco/trajectories_all.pkl\"\n",
    "\n",
    "# Pickle file path for trajectories with additional collumns filtered based on MIN_TRAJECTORY_POINTS\n",
    "FILTERED_TRAJECTORIES_FILE = \"../data/SanFrancisco/filtered_trajectories.pkl\"\n",
    "\n",
    "# Pickle file path for trajectories meant for training, with lat and lon only\n",
    "TRAIN_TRAJECTORIES_FILE = \"../data/SanFrancisco/train_trajectories.pkl\"\n",
    "\n",
    "# Pickle file path for trajectories meant for training\n",
    "TRAIN_TRAJECTORIES_TIME_DIFF_FILE = \"../data/SanFrancisco/train_trajectories_time_diff.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2f03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EARTH_RADIUS_KM = 6371\n",
    "EARTH_RADIUS_M  = 6371008.7714\n",
    "\n",
    "# Minimum number of points in a trajectory. A trajectory with less then MIN_TRAJECTORY_POINTS is dropped\n",
    "MIN_TRAJECTORY_POINTS = 25 \n",
    "\n",
    "# Parameter to filter trajectories. Used to check if haversine distance between two points is under THRESHOLD_M\n",
    "THRESHOLD_M = 100\n",
    "\n",
    "# Parameter to filter trajectories. Allowed sampling time in seconds between trajectory points. Should be allowed 2x sampling rate.\n",
    "TIME_DIFF_THRESHOLD_S = 120\n",
    "\n",
    "# Parameter to filter trajectories. Maximum allowed speed between trajectory points in km.\n",
    "SPEED_KM_THRESHOLD = 150\n",
    "\n",
    "# The bounding box area of the city. Used to eliminate outlier/spike points outside city region.\n",
    "CITY_BOUNDING_BOX = {\"lat_min\": 37.274, \"lat_max\": 38.1, \"lon_min\":-122.602, \"lon_max\": -122.019}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc4e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, file_path):\n",
    "    \"\"\"\n",
    "    Save python object obj in the given file_path with pickle.\n",
    "\n",
    "    :param object obj: Python object to be saved\n",
    "    :param str file_path: Path where to save obj\n",
    "    :return: If the save was successful\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "\n",
    "    if obj is not None and file_path is not None:\n",
    "\n",
    "        with open(file_path, 'wb') as file:\n",
    "            pickle.dump(obj, file)\n",
    "\n",
    "        return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103ca60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(file_path, encoding=None):\n",
    "    \"\"\"\n",
    "    To be used after calling save_object().\n",
    "    Loads a python object that was pickled with save_object()\n",
    "\n",
    "    :param str file_path: Path to the pickled\n",
    "    :param str encoding: None or type of file encoding\n",
    "    :return: None if load fails, else the pickled object\n",
    "    :rtype: None if fails or type of objected pickled with save_object() \n",
    "    \"\"\"\n",
    "    \n",
    "    if file_path is not None:\n",
    "\n",
    "        with open(file_path, 'rb') as file:\n",
    "\n",
    "            if encoding is not None:\n",
    "                return pickle.load(file, encoding='latin1')\n",
    "            else:\n",
    "                return pickle.load(file)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b19eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_to_datetime(unix_timestamp):\n",
    "    \"\"\"\n",
    "    Converts a unix timestamp into date and time.\n",
    "    \n",
    "    Example:\n",
    "        unix_time: 1744097710\n",
    "        gives\n",
    "        date: 2025-08-04\n",
    "        time: 07:35:10\n",
    "\n",
    "    :param int unix_timestamp: Unix time as int\n",
    "    :return: Tuple containing the date and time from unix_timestamp\n",
    "    :rtype: touple\n",
    "    \"\"\"\n",
    "    dt = datetime.fromtimestamp(unix_timestamp, tz=timezone.utc)\n",
    "\n",
    "    date = dt.strftime(\"%Y-%m-%d\")\n",
    "    time = dt.strftime('%H:%M:%S')\n",
    "\n",
    "    return date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b4c23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv():\n",
    "    \"\"\"\n",
    "    Processes input files from the San Francisco dataset.\n",
    "    Extracts trajectories based on the \"occupancy\" field.\n",
    "    Adds date and time for each point in a trajectory.\n",
    "\n",
    "    :return: A tuple containing four lists of dataframes:\n",
    "                original: Original data without filtering based on occupancy\n",
    "                occupied_trajectories: Trajectories based on occupancy=1\n",
    "                not_occupied_trajectories: Trajectories based on occupancy=0\n",
    "                trajectories: All trajectory with occupancy 1 and 0\n",
    "    \"\"\"\n",
    "    current_trajectory = []\n",
    "    original = []\n",
    "    trajectories = []\n",
    "    occupied_trajectories = []\n",
    "    not_occupied_trajectories = []\n",
    "\n",
    "    for i, f_name in enumerate(INPUT_FILES):\n",
    "        df_original = pd.read_csv(f_name, sep=\" \", names=[\"lat\", \"lon\", \"occupancy\", \"timestamp\"])\n",
    "        df_original = df_original.astype({\"lat\": float, \"lon\": float, \"occupancy\": int, \"timestamp\": int})\n",
    "\n",
    "        df_copy = df_original.copy()\n",
    "        df_copy[[\"date\", \"time\"]] = df_copy[\"timestamp\"].apply(timestamp_to_datetime).apply(pd.Series)\n",
    "\n",
    "        original.append(df_copy)\n",
    "\n",
    "        current_trajectory = []\n",
    "        current_occupancy = df_copy.iloc[0][\"occupancy\"] if not df_copy.empty else None\n",
    "\n",
    "        for _, row in df_copy.iterrows():\n",
    "            if row[\"occupancy\"] == current_occupancy:\n",
    "                current_trajectory.append([row[\"lat\"], row[\"lon\"], row[\"timestamp\"], row[\"date\"], row[\"time\"]])\n",
    "            else:\n",
    "                # Save the current trajectory to the correct list\n",
    "                if current_trajectory:\n",
    "                    df_traj = pd.DataFrame(current_trajectory, columns=[\"lat\", \"lon\", \"timestamp\", \"date\", \"time\"])\n",
    "                    trajectories.append(df_traj)\n",
    "                    if current_occupancy == 1:\n",
    "                        occupied_trajectories.append(df_traj)\n",
    "                    else:\n",
    "                        not_occupied_trajectories.append(df_traj)\n",
    "                # Reset occupancy state\n",
    "                current_trajectory = [[row[\"lat\"], row[\"lon\"], row[\"timestamp\"], row[\"date\"], row[\"time\"]]]\n",
    "                current_occupancy = row[\"occupancy\"]\n",
    "\n",
    "        # Save final trajectory\n",
    "        if current_trajectory:\n",
    "            df_traj = pd.DataFrame(current_trajectory, columns=[\"lat\", \"lon\", \"timestamp\", \"date\", \"time\"])\n",
    "            trajectories.append(df_traj)\n",
    "\n",
    "            if current_occupancy == 1:\n",
    "                occupied_trajectories.append(df_traj)\n",
    "            else:\n",
    "                not_occupied_trajectories.append(df_traj)\n",
    "\n",
    "    return original, occupied_trajectories, not_occupied_trajectories, trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4070ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dataset(from_csv=False,\n",
    "                  get_original=False, \n",
    "                  get_trajectories=False,\n",
    "                  get_occupied=False,\n",
    "                  get_not_occupied=False):\n",
    "    \"\"\"\n",
    "    Helper function. Loads the required data based on the function parameters.\n",
    "    It can return data processed from csv or loaded from pickled files.\n",
    "\n",
    "    :param bool from_csv: If set to true, reads data from csv files, \n",
    "                            otherwise tries to load pickled files.\n",
    "                            If set to true, ignores next params set to true.\n",
    "    :param bool get_original: Can be used if from_csv=False. Loads pickled original data\n",
    "    :param bool get_trajectories:Can be used if from_csv=False. Loads pickled trajectories\n",
    "    :param bool get_occupied: Can be used if from_csv=False. Loads pickled occupied trajectories\n",
    "    :param bool get_not_occupied: Can be used if from_csv=False. Loads pickled not occupied trajectories\n",
    "    \"\"\"\n",
    "    original = None\n",
    "    occupied_trajectories = None\n",
    "    not_occupied_trajectories = None\n",
    "    trajectories = None\n",
    "\n",
    "    if from_csv:\n",
    "        original, occupied_trajectories, not_occupied_trajectories, trajectories = process_csv()\n",
    "        save_object(original, ORIGINAL_FILE)\n",
    "        save_object(occupied_trajectories, OCCUPIED_FILE)\n",
    "        save_object(not_occupied_trajectories, NOT_OCCUPIED_FILE)\n",
    "        save_object(trajectories, TRAJECTORIES_FILE)\n",
    "\n",
    "        return original, occupied_trajectories, not_occupied_trajectories, trajectories\n",
    "    else:\n",
    "        if get_original:\n",
    "            original = load_object(ORIGINAL_FILE)\n",
    "\n",
    "        if get_trajectories:\n",
    "            trajectories = load_object(TRAJECTORIES_FILE)\n",
    "\n",
    "        if get_occupied:\n",
    "            occupied_trajectories = load_object(OCCUPIED_FILE)\n",
    "\n",
    "        if get_not_occupied:\n",
    "            not_occupied_trajectories = load_object(NOT_OCCUPIED_FILE)\n",
    "\n",
    "        return original, occupied_trajectories, not_occupied_trajectories, trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ac7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Compute great-circle distance between two lat/lon points in km.\n",
    "    \"\"\"\n",
    "\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    return haversine_distances([[lat1, lon1], [lat2, lon2]])[0, 1] * EARTH_RADIUS_KM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea792058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_dist_speed(filtered_dataset):\n",
    "    \"\"\"\n",
    "    Populates each dataframe trajectory in filtered_dataset list with the columns: time_diff, distance_km, speed_km.\n",
    "\n",
    "    :param list filtered_dataset: List of dataframes that have lat, lon, timestamp as columns\n",
    "    :return: Returns a new list where each dataframe has the above mentioned additional columns\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_trajectories = []\n",
    "\n",
    "    for df in filtered_dataset:\n",
    "        df = df.copy()\n",
    "        df[\"lat_next\"]  = df[\"lat\"].shift(1)\n",
    "        df[\"lon_next\"] = df[\"lon\"].shift(1)\n",
    "        df[\"time_diff\"] = np.abs(df[\"timestamp\"].diff())\n",
    "\n",
    "        df.loc[1:,\"distance_km\"] = df[1:].apply(\n",
    "            lambda row: haversine_distance_km(row[\"lat\"], row[\"lon\"], row[\"lat_next\"], row[\"lon_next\"]), axis=1\n",
    "        )\n",
    "\n",
    "        df.loc[1:, \"speed_km\"] = df.loc[1:,\"distance_km\"] / (df.loc[1:,\"time_diff\"]/3600)\n",
    "\n",
    "        df = df.drop(columns=[\"lat_next\", \"lon_next\"])\n",
    "        filtered_trajectories.append(df)\n",
    "    \n",
    "    return filtered_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ebad603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_under_threshold(df, threshold_m=THRESHOLD_M):\n",
    "    \"\"\"\n",
    "    Usefull function to check if a given trajectory is in a given square \n",
    "    based on lat and lon min/max values. If the haversine distance in meters\n",
    "    is under threshold_m returns True, otherwise False.\n",
    "    \"\"\"\n",
    "\n",
    "    max = [ df[\"lat\"].max(), df[\"lon\"].max()] \n",
    "    min = [ df[\"lat\"].min(), df[\"lon\"].min()] \n",
    "\n",
    "    max_in_radians = [radians(_) for _ in max]\n",
    "    min_in_radians = [radians(_) for _ in min]\n",
    "\n",
    "\n",
    "    distance_m = haversine_distances([max_in_radians, min_in_radians]) * EARTH_RADIUS_M\n",
    "\n",
    "    if distance_m[0, 1] < threshold_m:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eacf2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trajectories_for_training(filtered_trajectories,\n",
    "                                    time_diff_threshold_s=TIME_DIFF_THRESHOLD_S,\n",
    "                                    max_min_threshold_m=THRESHOLD_M,\n",
    "                                    speed_km_threshold=SPEED_KM_THRESHOLD,\n",
    "                                    city_bounding_box=CITY_BOUNDING_BOX):\n",
    "    \"\"\"\n",
    "    Function to filter a list of dataframe trajectories based on several criteria:\n",
    "        - time_diff_threshold_s: Allowed sampling time in seconds between trajectory points. Should be allowed 2x sampling rate.\n",
    "        - max_min_threshold_m: Allowed distance in meters between lat and lon min/max. See trajectory_under_threshold().\n",
    "        - speed_km_threshold: Maximum allowed speed between trajectory points in km.\n",
    "        - city_bounding_box: The bounding box area of the city. Used to eliminate outlier/spike points outside city region.\n",
    "    \"\"\"\n",
    "    for_train_trajectories = []\n",
    "\n",
    "    for df in filtered_trajectories:\n",
    "\n",
    "        if (df[\"time_diff\"] > time_diff_threshold_s).any():\n",
    "            continue\n",
    "\n",
    "        if trajectory_under_threshold(df, threshold_m=max_min_threshold_m):\n",
    "            continue\n",
    "\n",
    "        if (df[\"speed_km\"] >= speed_km_threshold).any():\n",
    "            continue\n",
    "\n",
    "        mask_lat = df[\"lat\"].between(city_bounding_box[\"lat_min\"], city_bounding_box[\"lat_max\"]).all()\n",
    "        mask_lon = df[\"lon\"].between(city_bounding_box[\"lon_min\"], city_bounding_box[\"lon_max\"]).all()\n",
    "\n",
    "        if not mask_lat or not mask_lon:\n",
    "            continue\n",
    "\n",
    "        for_train_trajectories.append(df)\n",
    "    \n",
    "    return for_train_trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a08d0af1-3fb5-4d83-bbc5-81c428d9e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Loading\n",
    "The setup_dataset() function allows you to load original csv files, or based on function parameters to load already processed pickled files.\n",
    "\"\"\"\n",
    "_, _, _, trajectories = setup_dataset(get_trajectories=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d90a1",
   "metadata": {},
   "source": [
    "##### Trajectory count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46fcb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trajectories:928301\n",
      "Less then 5: 293261\n",
      "Between 5 and 10: 341024\n",
      "Between 10 and 20: 279743\n",
      "Between 20 and 30: 78556\n",
      "Between 30 and 40: 26836\n",
      "Over 40: 33767\n",
      "Over 25: 85361\n"
     ]
    }
   ],
   "source": [
    "traj_lengths = [len(df) for df in trajectories]\n",
    "\n",
    "less_than_5 = sum(1 for l in traj_lengths if l <= 5)\n",
    "between_5_10 = sum(1 for l in traj_lengths if 5 <= l <= 10)\n",
    "between_10_20 = sum(1 for l in traj_lengths if 10 <= l <= 20)\n",
    "between_20_30 = sum(1 for l in traj_lengths if 20 <= l <= 30)\n",
    "between_30_40 = sum(1 for l in traj_lengths if 30 <= l <= 40)\n",
    "over_40 = sum(1 for l in traj_lengths if l >= 40)\n",
    "over_25 = sum(1 for l in traj_lengths if l >= 25) # Current Sequence Lenght\n",
    "\n",
    "print(f\"Total Trajectories:{len(trajectories)}\")\n",
    "\n",
    "print(f\"Less then 5: {less_than_5}\")\n",
    "print(f\"Between 5 and 10: {between_5_10}\")\n",
    "print(f\"Between 10 and 20: {between_10_20}\")\n",
    "print(f\"Between 20 and 30: {between_20_30}\")\n",
    "print(f\"Between 30 and 40: {between_30_40}\")\n",
    "print(f\"Over 40: {over_40}\")\n",
    "print(f\"Over 25: {over_25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713a95c",
   "metadata": {},
   "source": [
    "##### Trajectory filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7f4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on minimum points needed in a trajectory\n",
    "# Change MIN_TRAJECTORY_POINTS in the **Configuration parameters** block to set the minimum number of points wanted in a trajectory.\n",
    "filtered_dataset = [df for df in trajectories if len(df['lat']) >= MIN_TRAJECTORY_POINTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4c98e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trajectories:928301\n",
      "Filter on sequence len 85361\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Trajectories:{len(trajectories)}\")\n",
    "print(f\"Filter on sequence len {len(filtered_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trajectories = compute_time_dist_speed(filtered_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e4bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_object(filtered_trajectories, FILTERED_TRAJECTORIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75b01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_trajectories = load_object(FILTERED_TRAJECTORIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6a00372",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_train_trajectories = filter_trajectories_for_training(filtered_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a49d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_train_trajectories_time_diff = [df.drop(columns=[\"timestamp\", \"date\", \"time\"]) for df in for_train_trajectories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "604ae16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_object(for_train_trajectories_time_diff, TRAIN_TRAJECTORIES_TIME_DIFF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3226e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectories after filtering 30351\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trajectories after filtering {len(for_train_trajectories)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a73e05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = [df.drop(columns=[\"time_diff\", \"timestamp\", \"distance_km\", \"speed_km\", \"date\", \"time\"]) for df in for_train_trajectories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d6b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_object(to_save, TRAIN_TRAJECTORIES_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
