{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1cde34d",
   "metadata": {},
   "source": [
    "# Generate Data Files\n",
    "\n",
    "This notebook generates normalized test data files for trajectory-based experiments using the Porto (or San Francisco) dataset. It loads raw trajectory data, filters and normalizes it, prepares input and output sequences for model testing, and saves the processed dataâ€”including test trajectories, sequence lengths, and normalization parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003dd67",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde37293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# oneDNN warning suppression TF 2.4.1\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import statistics\n",
    "\n",
    "from scipy.stats import energy_distance, wasserstein_distance\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from math import radians\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "from utils.data import *\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from models import *\n",
    "from apu_trajgen import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529140f7",
   "metadata": {},
   "source": [
    "## **Generate Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2794210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_dataset = \"PORTO\"\n",
    "selected_dataset = \"SANFRANCISCO\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7e803",
   "metadata": {},
   "source": [
    "#### **Load and Pre-process Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b8d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load trajectory data for faster execution\n",
    "data = load_data_from_pickle(DATASET[selected_dataset], TOTAL_TRAJS)\n",
    "\n",
    "subset = \"test\" # or \"train\" \n",
    "\n",
    "# Get the data in the selected square\n",
    "data = get_data_in_square(data = data, square = DATA_SQUARE[selected_dataset])\n",
    "\n",
    "# Get trajectories min and max values\n",
    "mins, maxs =  get_min_max_from_data(data)\n",
    "\n",
    "# Get number of trajectories\n",
    "num_of_traj = len(data)\n",
    "\n",
    "# Normalize the data using the min and max values\n",
    "normalization_ranges = {\"min\": mins, \"max\": maxs}\n",
    "\n",
    "# Only keep the lat and lon columns for now\n",
    "data = [data[i][COLUMNS] for i in range(num_of_traj)]\n",
    "\n",
    "# Normalize the data using scaler or normalization ranges\n",
    "scaler, data = normalize_trajectory_data(dataset = data, normalization_type = 'min-max')\n",
    "\n",
    "MAX_K = 1 # Maximum k value for the model MAX_K>=1\n",
    "\n",
    "# Create X and Y from the data\n",
    "X, Y =  create_X_Y_from_data(data, num_of_traj, k=MAX_K)\n",
    "\n",
    "# Train data preparation (the same format as the test data)\n",
    "X_test, Y_test, test_traj_seq_lengths = test_data_preparation(TRAINING_TESTING_SAME_FILE = TRAINING_TESTING_SAME_FILE,\n",
    "                                                                X = copy.deepcopy(X), Y = copy.deepcopy(Y),\n",
    "                                                                num_of_traj = num_of_traj,\n",
    "                                                                training_size = 0,\n",
    "                                                                SEQ_LEN = SEQ_LEN,\n",
    "                                                                NUM_FEATS = NUM_FEATS,\n",
    "                                                                TESTING_FILE = None,\n",
    "                                                                data = data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4229aa",
   "metadata": {},
   "source": [
    "#### **Save Files** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1224a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "\n",
    "save_pickle(X_test, DATA_FOLDER + selected_dataset.lower() + \"_X_\"+subset+\".pkl\")\n",
    "save_pickle(Y_test, DATA_FOLDER + selected_dataset.lower() + \"_Y_\"+subset+\".pkl\") \n",
    "\n",
    "# Save the sequence lengths of the test trajectories\n",
    "save_pickle(test_traj_seq_lengths, DATA_FOLDER + selected_dataset.lower() + \"_seq_len_\"+subset+\".pkl\") \n",
    "\n",
    "# Save the minimum and maximum values for each feature in your trajectory data\n",
    "save_pickle(normalization_ranges, DATA_FOLDER + selected_dataset.lower() + \"_normalization_ranges_\"+subset+\".pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
