{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d229a0b",
   "metadata": {},
   "source": [
    "# Metrics Computation\n",
    "\n",
    "This notebook computes and analyzes trajectory generation **privacy and utility** metrics for the APU-TrajGen2 model using the Porto or San Francisco datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df314923",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4303eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# oneDNN warning suppression TF 2.4.1\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import statistics\n",
    "\n",
    "from scipy.stats import energy_distance, wasserstein_distance\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from math import radians\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "from utils.data import *\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from models import *\n",
    "from apu_trajgen import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3861d1",
   "metadata": {},
   "source": [
    "##### **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9308f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dataset = \"PORTO\"\n",
    "# selected_dataset = \"SANFRANCISCO\"\n",
    "\n",
    "# Set the number of trajectories to process\n",
    "n_trajs = 10 # 5000\n",
    "\n",
    "mean_min = [80, 170, 250, 350] # privacy contraint\n",
    "mean_max = [155, 350, 450, 550] # utility contraint\n",
    "\n",
    "# grid_num = 6\n",
    "grid_num = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880fc46",
   "metadata": {},
   "source": [
    "##### **Metrics computations (fixed k)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aadbdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected dataset: PORTO\n",
      "grid_num: 20\n",
      "Method: APU-TrajGen2 - fixed k = 1\n",
      "---\n",
      "Mean Density Error:\n",
      "0.07926993386524774\n",
      "Mean Query Error:\n",
      "0.8886006023159305\n",
      "Mean Hotspot Query Error:\n",
      "0.5442095754346259\n",
      "Mean Coverage Kendall Tau:\n",
      "0.3358521303258145\n",
      "---\n",
      "Mean Trip Error:\n",
      "0.4158882483359762\n",
      "Mean Length Error:\n",
      "0.3327948025332016\n",
      "Mean Diameter Error:\n",
      "0.3138705462946926\n",
      "Mean Hausdorff:\n",
      "0.2197772261977661\n",
      "Mean DTW:\n",
      "3.146948045879319\n",
      "Mean EDR:\n",
      "0.0\n",
      "Mean Haversine distance (MDE):\n",
      "0.09466352382318971\n",
      "---\n",
      "Mean Pattern F1 Error:\n",
      "0.45\n",
      "Mean Pattern Support Error:\n",
      "0.45\n",
      "-------\n",
      "Mutual Information Score:\n",
      "2.9296613943464274\n",
      "##################################\n",
      "Method: APU-TrajGen2 - fixed k = 2\n",
      "---\n",
      "Mean Density Error:\n",
      "0.1468562801510516\n",
      "Mean Query Error:\n",
      "0.97143036384682\n",
      "Mean Hotspot Query Error:\n",
      "1.0\n",
      "Mean Coverage Kendall Tau:\n",
      "0.25144110275689224\n",
      "---\n",
      "Mean Trip Error:\n",
      "0.5545176644479682\n",
      "Mean Length Error:\n",
      "0.6931471305599506\n",
      "Mean Diameter Error:\n",
      "0.26009405639226046\n",
      "Mean Hausdorff:\n",
      "0.723837780834623\n",
      "Mean DTW:\n",
      "10.456060810655353\n",
      "Mean EDR:\n",
      "1.2\n",
      "Mean Haversine distance (MDE):\n",
      "0.31901832347547643\n",
      "---\n",
      "Mean Pattern F1 Error:\n",
      "0.20000000000000004\n",
      "Mean Pattern Support Error:\n",
      "0.725\n",
      "-------\n",
      "Mutual Information Score:\n",
      "2.880649804935662\n",
      "##################################\n",
      "Method: APU-TrajGen2 - fixed k = 3\n",
      "---\n",
      "Mean Density Error:\n",
      "0.25838555599361723\n",
      "Mean Query Error:\n",
      "1.1464012091507008\n",
      "Mean Hotspot Query Error:\n",
      "1.0\n",
      "Mean Coverage Kendall Tau:\n",
      "0.09469924812030076\n",
      "---\n",
      "Mean Trip Error:\n",
      "0.6931470805599603\n",
      "Mean Length Error:\n",
      "nan\n",
      "Mean Diameter Error:\n",
      "0.5367713882042651\n",
      "Mean Hausdorff:\n",
      "8.039145847129138\n",
      "Mean DTW:\n",
      "120.27755742041886\n",
      "Mean EDR:\n",
      "18.6\n",
      "Mean Haversine distance (MDE):\n",
      "2.6591744452481456\n",
      "---\n",
      "Mean Pattern F1 Error:\n",
      "0.18\n",
      "Mean Pattern Support Error:\n",
      "0.78\n",
      "-------\n",
      "Mutual Information Score:\n",
      "2.198887228596487\n",
      "##################################\n",
      "Method: APU-TrajGen2 - fixed k = 4\n",
      "---\n",
      "Mean Density Error:\n",
      "0.268736838052694\n",
      "Mean Query Error:\n",
      "0.6916571848274543\n",
      "Mean Hotspot Query Error:\n",
      "0.8558803990266194\n",
      "Mean Coverage Kendall Tau:\n",
      "0.08229323308270677\n",
      "---\n",
      "Mean Trip Error:\n",
      "0.6931470805599603\n",
      "Mean Length Error:\n",
      "nan\n",
      "Mean Diameter Error:\n",
      "nan\n",
      "Mean Hausdorff:\n",
      "20.341838757290454\n",
      "Mean DTW:\n",
      "253.22897118339424\n",
      "Mean EDR:\n",
      "24.4\n",
      "Mean Haversine distance (MDE):\n",
      "5.9417422260921375\n",
      "---\n",
      "Mean Pattern F1 Error:\n",
      "0.09\n",
      "Mean Pattern Support Error:\n",
      "0.78\n",
      "-------\n",
      "Mutual Information Score:\n",
      "1.603227905665058\n",
      "##################################\n",
      "Method: APU-TrajGen2 - fixed k = 5\n",
      "---\n",
      "Mean Density Error:\n",
      "0.3002630536617517\n",
      "Mean Query Error:\n",
      "0.8105171738820602\n",
      "Mean Hotspot Query Error:\n",
      "1.0\n",
      "Mean Coverage Kendall Tau:\n",
      "0.0218671679197995\n",
      "---\n",
      "Mean Trip Error:\n",
      "0.6931470805599603\n",
      "Mean Length Error:\n",
      "nan\n",
      "Mean Diameter Error:\n",
      "nan\n",
      "Mean Hausdorff:\n",
      "22.98770415822341\n",
      "Mean DTW:\n",
      "251.60896917476538\n",
      "Mean EDR:\n",
      "25.6\n",
      "Mean Haversine distance (MDE):\n",
      "6.29854195856771\n",
      "---\n",
      "Mean Pattern F1 Error:\n",
      "0.04\n",
      "Mean Pattern Support Error:\n",
      "0.8\n",
      "-------\n",
      "Mutual Information Score:\n",
      "1.3061302837602047\n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected dataset: \" + selected_dataset)\n",
    "print(\"grid_num: \" + str(grid_num))\n",
    "\n",
    "# Load the data and plot trajectory with id=traj_idx\n",
    "Y_test = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_test_fixed_k_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "test_seq_len = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_test_seq_len_fixed_k_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "\n",
    "normalization_ranges = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_normalization_ranges_test.pkl\") # the scaler used to normalize the data\n",
    "normalization_ranges = {\"min\": normalization_ranges[\"min\"][0:2], \"max\": normalization_ranges[\"max\"][0:2]}\n",
    "\n",
    "# Denormalize the data using the scaler or normalization ranges\n",
    "Y_test_dn = denormalize_data(dataset = copy.deepcopy(Y_test), normalization_ranges = normalization_ranges)\n",
    "Y_test_dn_list = array_to_list(Y_test_dn)\n",
    "\n",
    "# Transform the data to grid\n",
    "min_x, min_y, max_x, max_y = compute_min_max_coordinates(Y_test_dn)\n",
    "grid_map = grid.GridMap(grid_num, min_x, min_y, max_x, max_y)\n",
    "Y_test_dn_grid = convert_raw_to_grid(Y_test_dn_list, grid_map, interp=True)\n",
    "Y_test_dn_sampled = convert_grid_to_raw(Y_test_dn_grid) \n",
    "\n",
    "for k in range(1, 6):\n",
    "    \n",
    "    Y_pred_k = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_pred_fixed_k_\" + str(k) +\"_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "    \n",
    "    # Denormalize the data using the scaler or normalization ranges\n",
    "    Y_pred_k_dn = denormalize_data(dataset = Y_pred_k, normalization_ranges = normalization_ranges)\n",
    "    \n",
    "    Y_pred_dn_list = array_to_list(Y_pred_k_dn)\n",
    "    Y_pred_dn_grid = convert_raw_to_grid(Y_pred_dn_list, grid_map,interp=True)\n",
    "    \n",
    "    test_density = get_real_density(Y_test_dn_grid, grid_map)\n",
    "    pred_density = get_real_density(Y_pred_dn_grid, grid_map)\n",
    "    test_density /= np.sum(test_density)\n",
    "    pred_density /= np.sum(pred_density)\n",
    "    density_error = compute_js_distance_prob(test_density, pred_density)\n",
    "\n",
    "    # Compute Relative Query Error')\n",
    "    queries = [SquareQuery(grid_map.min_x, grid_map.min_y, grid_map.max_x, grid_map.max_y, size_factor=9) for _ in range(200)]\n",
    "    query_error = experiment.calculate_point_query(Y_test_dn_sampled,\n",
    "                                                Y_pred_dn_list,\n",
    "                                                queries)\n",
    "\n",
    "    # Compute Hotspot Query Error\n",
    "    hotspot_ndcg = experiment.calculate_hotspot_ndcg(test_density, pred_density)\n",
    "    hotspot_qerr = 1 - hotspot_ndcg\n",
    "\n",
    "    # # Compute Kendall-tau\n",
    "    kendall_tau = calculate_coverage_kendall_tau(Y_test_dn_grid,\n",
    "                                                            Y_pred_dn_grid,\n",
    "                                                            grid_map)\n",
    "\n",
    "    # Compute Trip error\n",
    "    test_trip_dist, _, _ = get_start_end_dist(Y_test_dn_grid, grid_map)\n",
    "    pred_trip_dist, _, _ = get_start_end_dist(Y_pred_dn_grid, grid_map)\n",
    "\n",
    "    test_trip_dist = np.asarray(test_trip_dist) / np.sum(test_trip_dist)\n",
    "    pred_trip_dist = np.asarray(pred_trip_dist) / np.sum(pred_trip_dist)\n",
    "    trip_error = compute_js_distance_prob(test_trip_dist, pred_trip_dist)\n",
    "\n",
    "    # Compute Length error\n",
    "    length_error = experiment.calculate_length_error(Y_test_dn_list, Y_pred_dn_list)\n",
    "\n",
    "    # Compute Diameter error\n",
    "    diameter_error = experiment.calculate_diameter_error(Y_test_dn_list, Y_pred_dn_list, bucket_num=grid_num,\n",
    "                                                        multi=False)\n",
    "\n",
    "    # Pattern mining errors\n",
    "    test_pattern = experiment.mine_patterns(Y_test_dn_grid)\n",
    "    pred_pattern = experiment.mine_patterns(Y_pred_dn_grid)\n",
    "\n",
    "    pattern_f1_error = experiment.calculate_pattern_f1_error(test_pattern, pred_pattern)\n",
    "    pattern_support_error = experiment.calculate_pattern_support(test_pattern, pred_pattern)\n",
    "    #\n",
    "\n",
    "    haversine_dists = []\n",
    "    haus_dists = []\n",
    "    edr_dists = []\n",
    "    dtw_dists = []\n",
    "    kendalltau_coeffs = []\n",
    "    js_dists = []\n",
    "    mi_scores = []\n",
    "    kl_divs = []\n",
    "\n",
    "\n",
    "    for traj_idx in range(len(Y_test_dn)):\n",
    "            \n",
    "        # Trajectory-level metrics\n",
    "        # Haversine point-to-point distance\n",
    "        haversine = compute_point_to_point_haversine_distances(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=float), Y_pred_k_dn[traj_idx])\n",
    "        \n",
    "        # Jensen-Shannon distance\n",
    "        js_dist = compute_js_distance(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=float), Y_pred_k_dn[traj_idx])\n",
    "        # KL divergence\n",
    "        kl_div = compute_kl_divergence(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=float), Y_pred_k_dn[traj_idx])\n",
    "        \n",
    "        # Mutual Information Score\n",
    "        mi_score = mutual_information_gps(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=float), Y_pred_k_dn[traj_idx],\n",
    "                                          n_lat_bins=grid_num, n_lon_bins=grid_num)\n",
    "        #\n",
    "\n",
    "        haversine_dists.append(np.mean(haversine))\n",
    "        \n",
    "        js_dists.append(js_dist)\n",
    "        kl_divs.append(kl_div)\n",
    "        mi_scores.append(mi_score)\n",
    "        \n",
    "        # Hausdorff distance\n",
    "        hdist = dst_utils_tsgan.hausdorff_distance(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=float) , Y_pred_k_dn[traj_idx], distance=\"haversine\")\n",
    "\n",
    "        # EDR distance\n",
    "        edr = dst_utils_tsgan.edit_distance(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], Y_pred_k_dn[traj_idx], eps=0.01)\n",
    "        # DTW distance\n",
    "        dtw, path = fastdtw(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], Y_pred_k_dn[traj_idx], dist=haversine_dist_in_km)\n",
    "        \n",
    "        haus_dists.append(hdist)\n",
    "        edr_dists.append(edr)\n",
    "        dtw_dists.append(dtw)\n",
    "        \n",
    "\n",
    "    print(\"Method: APU-TrajGen2 - fixed k = \"+ str(k))\n",
    "    print(\"---\")\n",
    "    print(\"Mean Density Error:\")\n",
    "    print(density_error)\n",
    "    print(\"Mean Query Error:\")\n",
    "    print(query_error)\n",
    "    print(\"Mean Hotspot Query Error:\")\n",
    "    print(hotspot_qerr)\n",
    "    print(\"Mean Coverage Kendall Tau:\")\n",
    "    print(kendall_tau)\n",
    "    print(\"---\")\n",
    "    print(\"Mean Trip Error:\")\n",
    "    print(trip_error)\n",
    "    print(\"Mean Length Error:\")\n",
    "    print(length_error) \n",
    "    print(\"Mean Diameter Error:\")\n",
    "    print(diameter_error) \n",
    "    print(\"Mean Hausdorff:\")\n",
    "    print(np.mean(haus_dists))\n",
    "    print(\"Mean DTW:\")\n",
    "    print(np.mean(dtw_dists)) \n",
    "    print(\"Mean EDR:\")\n",
    "    print(np.mean(edr_dists))\n",
    "    print(\"Mean Haversine distance (MDE):\")\n",
    "    print(np.mean(haversine_dists)/1000)  # Convert to km\n",
    "    print(\"---\")\n",
    "    print(\"Mean Pattern F1 Error:\")\n",
    "    print(pattern_f1_error)\n",
    "    print(\"Mean Pattern Support Error:\")\n",
    "    print(pattern_support_error)\n",
    "    print(\"-------\")\n",
    "    print(\"Mutual Information Score:\")\n",
    "    print(np.mean(mi_scores))\n",
    "    \n",
    "    print(\"##################################\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e68821c",
   "metadata": {},
   "source": [
    "##### **Metrics computations (adaptive k)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80be1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected dataset: PORTO\n",
      "grid_num: 20\n",
      "Targeted mean: \n",
      "Mean min: 80 / Mean max: 155\n",
      "Mean Haversine distance:\n",
      "125.9867273274228\n",
      "Mean DTW:\n",
      "4.25921089685239\n",
      "Mean Hausdorff:\n",
      "0.2784359745766815\n",
      "Mean EDR:\n",
      "0.0\n",
      "Mean Jensen-Shannon Distance (JDS):\n",
      "nan\n",
      "Mean KL Divergence:\n",
      "nan\n",
      "---\n",
      "Mean Density Error:\n",
      "0.141094674412876\n",
      "Mean Relative Query Error:\n",
      "0.08607233627932148\n",
      "Mean Hotspot Query Error:\n",
      "0.8786144122119879\n",
      "Mean Kendall Tau:\n",
      "0.59293631931138\n",
      "Mean Trip Error:\n",
      "0.21368109576587047\n",
      "Mean Length Error:\n",
      "0.38663454193271096\n",
      "Mean Diameter Error:\n",
      "0.40051394386468514\n",
      "Mean Pattern F1 Error:\n",
      "0.27\n",
      "Mean Pattern Support Error:\n",
      "0.685\n",
      "-------\n",
      "Mutual Information Score:\n",
      "2.8915529233692143\n",
      "---\n",
      "Number of trajectories with MDE in range: 10 / 10\n",
      "Accuracy/Percentage of trajectories with MDE in range: 100.0%\n",
      "Standard deviation of Haversine distances: 12.275904447842167\n",
      "##################################\n",
      "Targeted mean: \n",
      "Mean min: 170 / Mean max: 350\n",
      "Mean Haversine distance:\n",
      "244.0869101543226\n",
      "Mean DTW:\n",
      "8.348498061521758\n",
      "Mean Hausdorff:\n",
      "0.4852684746542195\n",
      "Mean EDR:\n",
      "0.0\n",
      "Mean Jensen-Shannon Distance (JDS):\n",
      "nan\n",
      "Mean KL Divergence:\n",
      "nan\n",
      "---\n",
      "Mean Density Error:\n",
      "0.19221762974160378\n",
      "Mean Relative Query Error:\n",
      "0.09795837554104192\n",
      "Mean Hotspot Query Error:\n",
      "0.8389134567967316\n",
      "Mean Kendall Tau:\n",
      "0.5537289563396091\n",
      "Mean Trip Error:\n",
      "0.21368109576587047\n",
      "Mean Length Error:\n",
      "0.6931471255599511\n",
      "Mean Diameter Error:\n",
      "0.31200650984455447\n",
      "Mean Pattern F1 Error:\n",
      "0.20999999999999996\n",
      "Mean Pattern Support Error:\n",
      "0.775\n",
      "-------\n",
      "Mutual Information Score:\n",
      "2.9086783170895547\n",
      "---\n",
      "Number of trajectories with MDE in range: 10 / 10\n",
      "Accuracy/Percentage of trajectories with MDE in range: 100.0%\n",
      "Standard deviation of Haversine distances: 27.824641726228162\n",
      "##################################\n",
      "Targeted mean: \n",
      "Mean min: 250 / Mean max: 450\n",
      "Mean Haversine distance:\n",
      "328.90956995123753\n",
      "Mean DTW:\n",
      "11.149694867010844\n",
      "Mean Hausdorff:\n",
      "0.6554399314163382\n",
      "Mean EDR:\n",
      "0.3\n",
      "Mean Jensen-Shannon Distance (JDS):\n",
      "nan\n",
      "Mean KL Divergence:\n",
      "nan\n",
      "---\n",
      "Mean Density Error:\n",
      "0.1727617077880787\n",
      "Mean Relative Query Error:\n",
      "0.1874530045606464\n",
      "Mean Hotspot Query Error:\n",
      "1.0\n",
      "Mean Kendall Tau:\n",
      "0.447775605531585\n",
      "Mean Trip Error:\n",
      "0.21368109576587047\n",
      "Mean Length Error:\n",
      "0.6931471355599503\n",
      "Mean Diameter Error:\n",
      "0.27684120549428476\n",
      "Mean Pattern F1 Error:\n",
      "0.20000000000000004\n",
      "Mean Pattern Support Error:\n",
      "0.75\n",
      "-------\n",
      "Mutual Information Score:\n",
      "2.841597746072534\n",
      "---\n",
      "Number of trajectories with MDE in range: 10 / 10\n",
      "Accuracy/Percentage of trajectories with MDE in range: 100.0%\n",
      "Standard deviation of Haversine distances: 35.24055594884706\n",
      "##################################\n",
      "Targeted mean: \n",
      "Mean min: 350 / Mean max: 550\n",
      "Mean Haversine distance:\n",
      "563.6997690752146\n",
      "Mean DTW:\n",
      "20.23099766173324\n",
      "Mean Hausdorff:\n",
      "0.9661971121470542\n",
      "Mean EDR:\n",
      "4.4\n",
      "Mean Jensen-Shannon Distance (JDS):\n",
      "nan\n",
      "Mean KL Divergence:\n",
      "nan\n",
      "---\n",
      "Mean Density Error:\n",
      "0.31957794648130783\n",
      "Mean Relative Query Error:\n",
      "0.27019986204154284\n",
      "Mean Hotspot Query Error:\n",
      "1.0\n",
      "Mean Kendall Tau:\n",
      "0.4149752436370856\n",
      "Mean Trip Error:\n",
      "0.21368109576587047\n",
      "Mean Length Error:\n",
      "nan\n",
      "Mean Diameter Error:\n",
      "0.32204030204078093\n",
      "Mean Pattern F1 Error:\n",
      "0.07\n",
      "Mean Pattern Support Error:\n",
      "0.925\n",
      "-------\n",
      "Mutual Information Score:\n",
      "2.881034546016223\n",
      "---\n",
      "Number of trajectories with MDE in range: 4 / 10\n",
      "Accuracy/Percentage of trajectories with MDE in range: 40.0%\n",
      "Standard deviation of Haversine distances: 165.1043911759578\n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "print(\"Selected dataset: \" + selected_dataset)\n",
    "print(\"grid_num: \" + str(grid_num))\n",
    "\n",
    "# Load the data \n",
    "Y_test = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_test_adaptive_k_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "test_seq_len = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_test_seq_len_adaptive_k_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "\n",
    "normalization_ranges = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_normalization_ranges_test.pkl\") # the scaler used to normalize the data\n",
    "normalization_ranges = {\"min\": normalization_ranges[\"min\"][0:2], \"max\": normalization_ranges[\"max\"][0:2]}\n",
    "\n",
    "# Denormalize the data using the scaler or normalization ranges\n",
    "Y_test_dn = denormalize_data(dataset = copy.deepcopy(Y_test), normalization_ranges = normalization_ranges)\n",
    "\n",
    "# Transform the data to grid\n",
    "min_x, min_y, max_x, max_y = compute_min_max_coordinates(Y_test_dn)\n",
    "grid_map = grid.GridMap(grid_num, min_x, min_y, max_x, max_y)\n",
    "Y_test_dn_list = array_to_list(Y_test_dn)\n",
    "Y_test_dn_grid = convert_raw_to_grid(Y_test_dn_list, grid_map, interp=False)\n",
    "\n",
    "for mmin, mmax in zip(mean_min, mean_max):\n",
    "    \n",
    "    Y_pred_k = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_pred_adaptive_k_mean_min\" + str(mmin) \n",
    "             + \"_mean_max\" + str(mmax) + \"_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "    \n",
    "    # Denormalize the data using the scaler or normalization ranges\n",
    "    Y_pred_k_dn = denormalize_data(dataset = Y_pred_k, normalization_ranges = normalization_ranges)\n",
    "    \n",
    "    # Global level metrics\n",
    "    # Compute density error\n",
    "    Y_pred_dn_list = array_to_list(Y_pred_k_dn)\n",
    "    Y_pred_dn_grid = convert_raw_to_grid(Y_pred_dn_list, grid_map,interp=False)\n",
    "    test_density = get_real_density(Y_test_dn_grid, grid_map)\n",
    "    pred_density = get_real_density(Y_pred_dn_grid, grid_map)\n",
    "    test_density /= np.sum(test_density)\n",
    "    pred_density /= np.sum(pred_density)\n",
    "    density_error = compute_js_distance_prob(test_density, pred_density)\n",
    "    \n",
    "    # Compute Relative Query Error')\n",
    "\n",
    "    queries = [SquareQuery(grid_map.min_x, grid_map.min_y, grid_map.max_x, grid_map.max_y, size_factor=9) for _ in range(200)]\n",
    "    query_error = experiment.calculate_point_query(Y_test_dn_list,\n",
    "                                                Y_pred_dn_list,\n",
    "                                                queries)\n",
    "    \n",
    "    # Compute Hotspot Query Error\n",
    "    hotspot_ndcg = experiment.calculate_hotspot_ndcg(test_density, pred_density)\n",
    "    hotspot_qerr = 1 - hotspot_ndcg\n",
    "\n",
    "    # Compute Trip error\n",
    "    test_trip_dist, _, _ = get_start_end_dist(Y_test_dn_grid, grid_map)\n",
    "    pred_trip_dist, _, _ = get_start_end_dist(Y_pred_dn_grid, grid_map)\n",
    "\n",
    "    test_trip_dist = np.asarray(test_trip_dist) / np.sum(test_trip_dist)\n",
    "    pred_trip_dist = np.asarray(test_trip_dist) / np.sum(pred_trip_dist)\n",
    "    trip_error = compute_js_distance_prob(test_trip_dist, pred_trip_dist)\n",
    "    \n",
    "    # Compute Length error\n",
    "    length_error = experiment.calculate_length_error(Y_test_dn_list, Y_pred_dn_list)\n",
    "    \n",
    "    # Compute Diameter error\n",
    "    diameter_error = experiment.calculate_diameter_error(Y_test_dn_list, Y_pred_dn_list, bucket_num=grid_num,\n",
    "                                                        multi=False)\n",
    "\n",
    "    # Pattern mining errors\n",
    "    test_pattern = experiment.mine_patterns(Y_test_dn_grid)\n",
    "    pred_pattern = experiment.mine_patterns(Y_pred_dn_grid)\n",
    "\n",
    "    pattern_f1_error = experiment.calculate_pattern_f1_error(test_pattern, pred_pattern)\n",
    "    pattern_support_error = experiment.calculate_pattern_support(test_pattern, pred_pattern)\n",
    "    #\n",
    "    \n",
    "    haversine_dists = []\n",
    "    haus_dists = []\n",
    "    edr_dists = []\n",
    "    dtw_dists = []\n",
    "    kendalltau_coeffs = []\n",
    "    js_dists = []\n",
    "    mi_scores = []\n",
    "    kl_divs = []\n",
    " \n",
    "    n_mu_n = 0\n",
    "    n_traj = 0\n",
    "    \n",
    "    for traj_idx in range(n_trajs):\n",
    "        \n",
    "        # Trajectory-level metrics\n",
    "        # print(\"Trajectory: \" + str(traj_idx))\n",
    "        # Haversine point-to-point distance\n",
    "        if (len(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]]) == len(Y_pred_k_dn[traj_idx])):\n",
    "            haversine = compute_point_to_point_haversine_distances(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], Y_pred_k_dn[traj_idx])\n",
    "            \n",
    "            # Hausdorff distance\n",
    "            hdist = dst_utils_tsgan.hausdorff_distance(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=np.float32), np.array(Y_pred_k_dn[traj_idx], dtype=np.float32), distance=\"haversine\")\n",
    "            # EDR distance\n",
    "            edr = dst_utils_tsgan.edit_distance(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=np.float32), Y_pred_k_dn[traj_idx], eps=0.01)\n",
    "            # DTW distance\n",
    "            dtw, path = fastdtw(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=float), Y_pred_k_dn[traj_idx], dist=haversine_dist_in_km)\n",
    "            # Kendall Tau coefficients\n",
    "            \n",
    "            kt_coeff, kt_pval = compute_kendall_tau(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=float), Y_pred_k_dn[traj_idx])\n",
    "            \n",
    "            # Mutual Information Score\n",
    "\n",
    "            mi_score = mutual_information_gps(np.array(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], dtype=float), Y_pred_k_dn[traj_idx], n_lat_bins=grid_num, n_lon_bins=grid_num)\n",
    "            #\n",
    "\n",
    "            mean_dst = np.mean(haversine)\n",
    "            haversine_dists.append(mean_dst)\n",
    "            haus_dists.append(hdist)\n",
    "            edr_dists.append(edr)\n",
    "            dtw_dists.append(dtw)\n",
    "            kendalltau_coeffs.append(kt_coeff)\n",
    "            # js_dists.append(js_dist)\n",
    "            # kl_divs.append(kl_div)\n",
    "            mi_scores.append(mi_score)\n",
    "            \n",
    "            if (mean_dst >= mmin and mean_dst <=mmax):\n",
    "                n_mu_n = n_mu_n + 1\n",
    "            n_traj = n_traj + 1\n",
    "        else:\n",
    "            print(\"Trajectory lengths do not match for trajectory \" + str(traj_idx) + \". Skipping...\")\n",
    "            continue\n",
    "        \n",
    "\n",
    "    print(\"Targeted mean: \")\n",
    "    print(\"Mean min: \" + str(mmin) + \" / Mean max: \" + str(mmax))\n",
    "    print(\"Mean Haversine distance:\")\n",
    "    print(np.mean(haversine_dists))\n",
    "    print(\"Mean DTW:\")\n",
    "    print(np.mean(dtw_dists))\n",
    "    print(\"Mean Hausdorff:\")\n",
    "    print(np.mean(haus_dists))\n",
    "    print(\"Mean EDR:\")\n",
    "    print(np.mean(edr_dists))\n",
    "    print(\"Mean Jensen-Shannon Distance (JDS):\")\n",
    "    print(np.mean(js_dists))\n",
    "    print(\"Mean KL Divergence:\")\n",
    "    print(np.mean(kl_divs))\n",
    "    print(\"---\")\n",
    "    print(\"Mean Density Error:\")\n",
    "    print(density_error)\n",
    "    print(\"Mean Relative Query Error:\")\n",
    "    print(query_error)\n",
    "    print(\"Mean Hotspot Query Error:\")\n",
    "    print(hotspot_qerr)\n",
    "    print(\"Mean Kendall Tau:\")\n",
    "    print(np.mean(kendalltau_coeffs))\n",
    "    # print(\"Mean Coverage Kendall Tau:\")\n",
    "    # print(kendall_tau)\n",
    "    print(\"Mean Trip Error:\")\n",
    "    print(trip_error)\n",
    "    print(\"Mean Length Error:\")\n",
    "    print(length_error)\n",
    "    print(\"Mean Diameter Error:\")\n",
    "    print(diameter_error)\n",
    "    print(\"Mean Pattern F1 Error:\")\n",
    "    print(pattern_f1_error)\n",
    "    print(\"Mean Pattern Support Error:\")\n",
    "    print(pattern_support_error)\n",
    "    print(\"-------\")\n",
    "    print(\"Mutual Information Score:\")\n",
    "    print(np.mean(mi_scores))\n",
    "    print(\"---\")\n",
    "    print(\"Number of trajectories with MDE in range: \" + str(n_mu_n) + \" / \" + str(n_traj))\n",
    "    print(\"Accuracy/Percentage of trajectories with MDE in range: \" + str(n_mu_n / n_traj * 100) + \"%\")\n",
    "    print(\"Standard deviation of Haversine distances: \" + str(statistics.stdev(haversine_dists,xbar=(mmax+mmin)/2)))\n",
    "    print(\"##################################\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
