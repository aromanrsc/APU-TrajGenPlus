{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c969dbe",
   "metadata": {},
   "source": [
    "# Trajectory Reconstruction\n",
    "\n",
    "The robustness of the proposed approach is evaluated against adversarial attacks by simulating the reconstruction of real trajectories from the published synthetic trajectories using the same model, by computing the Reconstruction Error (RE).\n",
    "\n",
    "More details can be found in the research paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003dd67",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde37293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# oneDNN warning suppression TF 2.4.1\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tilemapbase\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "\n",
    "from utils.data import *\n",
    "from utils.plots import *\n",
    "from utils.metrics import *\n",
    "from models import *\n",
    "from apu_trajgen import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529140f7",
   "metadata": {},
   "source": [
    "## **Experiments (Porto dataset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d9f4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dataset = \"PORTO\"\n",
    "# The mde_k distances are computed in the trajgen-fixed-k.py script\n",
    "# They represent the MDE for k=1, k=2, k=3, and k=4 (computed for 5000 trajectories)\n",
    "# These values are used to determine the adaptive k values based on the privacy and utility constraints\n",
    "mde_k = [76, 257, 3585, 7185] # mean distances for k=1, k=2, k=3, and k=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7e803",
   "metadata": {},
   "source": [
    "#### **Load Model and Test Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a917cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data \n",
    "X_test = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_X_test.pkl\") # the input trajectory data\n",
    "Y_test = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_test.pkl\") # the test trajectory data\n",
    "test_seq_len = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_seq_len_test.pkl\") # the sequence lenght of the input trajectory data\n",
    "normalization_ranges = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_normalization_ranges_test.pkl\") # the scaler used to normalize the data\n",
    "\n",
    "normalization_ranges = {\"min\": normalization_ranges[\"min\"][0:2], \"max\": normalization_ranges[\"max\"][0:2]}\n",
    "\n",
    "# Save the model\n",
    "mdl = load_pickle( MODEL_FOLDER + \"mdlgru-\"+selected_dataset.lower()+\".pkl\")\n",
    "\n",
    "# Model for BS = 1\n",
    "model_sl = create_GRU_model(GRU_cells= LSTM_CELLS,\n",
    "                          seq_len = 1,\n",
    "                          num_feat = NUM_FEATS,\n",
    "                          batch_size = 1,\n",
    "                          stateful = True,\n",
    "                          return_seq = RETURN_SEQ,\n",
    "                          num_outputs = NUM_OUTPUTS,\n",
    "                          LR = LR,\n",
    "                          SEED = SEED,\n",
    "                          ragged = False)\n",
    "\n",
    "\n",
    "# Set weights and states\n",
    "model_sl.set_weights(mdl.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bbb9d",
   "metadata": {},
   "source": [
    "#### **Reconstruct trajectories** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b8d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing trajectories with mean_min = 80 and mean_max = 155\n",
      "Processing trajectories with mean_min = 170 and mean_max = 350\n",
      "Processing trajectories with mean_min = 250 and mean_max = 450\n",
      "Processing trajectories with mean_min = 350 and mean_max = 550\n"
     ]
    }
   ],
   "source": [
    "# Recontruct the trajectories from the predictions\n",
    "\n",
    "selected_dataset = \"PORTO\"\n",
    "\n",
    "mean_min = [80, 170, 250, 350] # privacy contraint\n",
    "mean_max = [155, 350, 450, 550] # utility contraint\n",
    "\n",
    "k_means = [76, 257, 3585, 7185]\n",
    "\n",
    "n_trajs = 10\n",
    "\n",
    "for mmin, mmax in zip(mean_min, mean_max):\n",
    "        \n",
    "    print(\"Processing trajectories with mean_min = \" + str(mmin) + \" and mean_max = \" + str(mmax))\n",
    "    \n",
    "    normalization_ranges = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_normalization_ranges_test.pkl\") # the scaler used to normalize the data\n",
    "    normalization_ranges = {\"min\": normalization_ranges[\"min\"][0:2], \"max\": normalization_ranges[\"max\"][0:2]}\n",
    "        \n",
    "    for i in range(len(k_means)):\n",
    "        if k_means[i] > mmin:\n",
    "                k_min = i+1\n",
    "                break\n",
    "    k_max = k_min + round((mmax-mmin)/k_means[0]) + 1\n",
    "\n",
    "    Y_pred_k = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_pred_adaptive_k_mean_min\" + str(mmin) \n",
    "            + \"_mean_max\" + str(mmax) + \"_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "    \n",
    "    Y_pred_k = add_speed_column(Y_pred_k, time_diff_seconds=15)  # The sampling rate of 15 seconds\n",
    "    \n",
    "    data = []\n",
    "    for arr in Y_pred_k:\n",
    "        df = pd.DataFrame(arr, columns=COLUMNS_INPUT)\n",
    "        data.append(df)\n",
    "\n",
    "    # # Normalize the data using scaler or normalization ranges\n",
    "    # scaler, data = normalize_trajectory_data(dataset = data, normalization_type = \"min-max\")\n",
    "    data = min_max_normalize_third_column(data)\n",
    "\n",
    "    num_of_traj = len(Y_pred_k)\n",
    "    # # Create X and Y from the data\n",
    "    X, Y =  create_X_Y_from_data(data, num_of_traj, k=1)\n",
    "\n",
    "    # Train Data Preparation (the same format as the test data)\n",
    "    X_pred_k, Y_pred_k, test_traj_seq_lengths = test_data_preparation(TRAINING_TESTING_SAME_FILE = TRAINING_TESTING_SAME_FILE,\n",
    "                                                                    X = copy.deepcopy(X), Y = copy.deepcopy(Y),\n",
    "                                                                    num_of_traj = num_of_traj,\n",
    "                                                                    training_size = 0,\n",
    "                                                                    SEQ_LEN = SEQ_LEN,\n",
    "                                                                    NUM_FEATS = NUM_FEATS,\n",
    "                                                                    TESTING_FILE = None,\n",
    "                                                                    data = data)\n",
    "    \n",
    "    \n",
    "    Y_reconstructed_k = apu_trajgen_adaptive_k(mdl = model_sl,\n",
    "                                            X_t = copy.deepcopy(X_pred_k),\n",
    "                                            test_traj_seq_lengths = test_traj_seq_lengths,\n",
    "                                            SEQ_LENGTH = 1,\n",
    "                                            NUM_FEATS = NUM_FEATS,\n",
    "                                            su_funct = compute_su_score1,\n",
    "                                            su_funct_args={\"mean_min\": mmin, \"mean_max\": mmax},\n",
    "                                            normalization_ranges = normalization_ranges,\n",
    "                                            k_min = k_min,\n",
    "                                            k_max = k_max,\n",
    "                                            save_results = False)\n",
    "    \n",
    "    save_pickle(Y_reconstructed_k, DATA_FOLDER + selected_dataset.lower() + \"_Y_reconstructed_adaptive_k_mean_min\" + str(mmin) \n",
    "            + \"_mean_max\" + str(mmax) + \"_ntrajs_\" + str(n_trajs) + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa8aee",
   "metadata": {},
   "source": [
    "#### **Plot trajectories** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "664f8fe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_trajectory_map_attack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m dists_k \u001b[38;5;241m=\u001b[39m compute_point_to_point_haversine_distances(Y_test_dn[traj_idx][\u001b[38;5;241m0\u001b[39m:test_seq_len[traj_idx]], Y_pred_k_dn[traj_idx])\n\u001b[1;32m     37\u001b[0m dists_k_reconstructed \u001b[38;5;241m=\u001b[39m compute_point_to_point_haversine_distances(Y_test_dn[traj_idx][\u001b[38;5;241m1\u001b[39m:test_seq_len[traj_idx]], Y_reconstructed_k_dn[traj_idx])\n\u001b[0;32m---> 39\u001b[0m \u001b[43mplot_trajectory_map_attack\u001b[49m(actual_norm \u001b[38;5;241m=\u001b[39m Y_test_dn[traj_idx][\u001b[38;5;241m1\u001b[39m:test_seq_len[traj_idx]],\n\u001b[1;32m     40\u001b[0m                     predicted_norm  \u001b[38;5;241m=\u001b[39m Y_pred_k_dn[traj_idx][\u001b[38;5;241m1\u001b[39m:test_seq_len[traj_idx]],\n\u001b[1;32m     41\u001b[0m                     attack_norm \u001b[38;5;241m=\u001b[39m Y_reconstructed_k_dn[traj_idx],\n\u001b[1;32m     42\u001b[0m                     dists_p \u001b[38;5;241m=\u001b[39m dists_k,\n\u001b[1;32m     43\u001b[0m                     dists_a \u001b[38;5;241m=\u001b[39m dists_k_reconstructed,\n\u001b[1;32m     44\u001b[0m                     dist_min \u001b[38;5;241m=\u001b[39m mmin,\n\u001b[1;32m     45\u001b[0m                     dist_max \u001b[38;5;241m=\u001b[39m mmax,\n\u001b[1;32m     46\u001b[0m                     aspect_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.2\u001b[39m,\n\u001b[1;32m     47\u001b[0m                     adaptive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m                     traj_id \u001b[38;5;241m=\u001b[39m traj_idx,\n\u001b[1;32m     49\u001b[0m                     scatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m                     savePath \u001b[38;5;241m=\u001b[39m DATA_FOLDER \u001b[38;5;241m+\u001b[39m selected_dataset\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_reconstructed_mean_min\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(mmin) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_mean_max\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(mmax) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_trajid_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(traj_idx))\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoint-to-point distance between the real and protected trajectory:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m (dists_k)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_trajectory_map_attack' is not defined"
     ]
    }
   ],
   "source": [
    "# Select a trajectory to visualize\n",
    "traj_idx = 5\n",
    "\n",
    "n_trajs = 10\n",
    "\n",
    "\n",
    "mean_min = [80, 170, 250, 350] # privacy contraint\n",
    "mean_max = [155, 350, 450, 550] # utility contraint\n",
    "\n",
    "# Load the data and plot trajectory with id=traj_idx\n",
    "Y_test = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_test_adaptive_k_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "test_seq_len = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_test_seq_len_adaptive_k_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "\n",
    "for mmin, mmax in zip(mean_min, mean_max):\n",
    "        \n",
    "    normalization_ranges = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_normalization_ranges_test.pkl\") # the scaler used to normalize the data\n",
    "    \n",
    "    normalization_ranges = {\"min\": normalization_ranges[\"min\"][0:2], \"max\": normalization_ranges[\"max\"][0:2]}\n",
    "    \n",
    "    Y_test_dn = denormalize_data(dataset = copy.deepcopy(Y_test), normalization_ranges = normalization_ranges)\n",
    "    \n",
    "    Y_pred_k = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_pred_adaptive_k_mean_min\" + str(mmin) \n",
    "            + \"_mean_max\" + str(mmax) + \"_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "    \n",
    "    # Denormalize the data using the scaler or normalization ranges\n",
    "    Y_pred_k_dn = denormalize_data(dataset = Y_pred_k, normalization_ranges = normalization_ranges) \n",
    "    \n",
    "    Y_reconstructed_k = load_pickle(DATA_FOLDER + selected_dataset.lower() + \"_Y_reconstructed_adaptive_k_mean_min\" + str(mmin) \n",
    "            + \"_mean_max\" + str(mmax) + \"_ntrajs_\" + str(n_trajs) + \".pkl\")\n",
    "    \n",
    "    Y_reconstructed_k = Y_reconstructed_k[0]\n",
    "    \n",
    "    Y_reconstructed_k_dn = denormalize_data(dataset = Y_reconstructed_k, normalization_ranges = normalization_ranges) \n",
    "    \n",
    "    dists_k = compute_point_to_point_haversine_distances(Y_test_dn[traj_idx][0:test_seq_len[traj_idx]], Y_pred_k_dn[traj_idx])\n",
    "    \n",
    "    dists_k_reconstructed = compute_point_to_point_haversine_distances(Y_test_dn[traj_idx][1:test_seq_len[traj_idx]], Y_reconstructed_k_dn[traj_idx])\n",
    "\n",
    "    plot_trajectory_map_attack(actual_norm = Y_test_dn[traj_idx][1:test_seq_len[traj_idx]],\n",
    "                        predicted_norm  = Y_pred_k_dn[traj_idx][1:test_seq_len[traj_idx]],\n",
    "                        attack_norm = Y_reconstructed_k_dn[traj_idx],\n",
    "                        dists_p = dists_k,\n",
    "                        dists_a = dists_k_reconstructed,\n",
    "                        dist_min = mmin,\n",
    "                        dist_max = mmax,\n",
    "                        aspect_ratio = 2.2,\n",
    "                        adaptive = True,\n",
    "                        traj_id = traj_idx,\n",
    "                        scatter = True,\n",
    "                        savePath = DATA_FOLDER + selected_dataset.lower() + \"_reconstructed_mean_min\" + str(mmin) + \"_mean_max\" + str(mmax) + \"_trajid_\" + str(traj_idx))\n",
    "    print(\"Point-to-point distance between the real and protected trajectory:\")\n",
    "    print (dists_k)\n",
    "    print(\"##################################\")\n",
    "    print(\"Targeted mean: \")\n",
    "    print(\"Mean min: \" + str(mmin) + \" / Mean max: \" + str(mmax))\n",
    "    print(\"Mean distance between the real and protected trajectory:\")\n",
    "    print(np.mean(dists_k))\n",
    "    print(\"Mean distance between the real and reconstructed trajectory:\")\n",
    "    print(np.mean(dists_k_reconstructed))\n",
    "    print(\"##################################\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
